<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport"    content="width=device-width, initial-scale=1">
<meta name="description" content="">
<meta name="author"      content="">

<link href="atom.xml" type="application/atom+xml" rel="alternate" title="Atom feed for R’alf Dev Log" />

<meta property="og:url"         content="http://www.alfray.com/ralf/blog/dev/2020-07-15_track_detection_opencv.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Track Detection & OpenCV" />

<meta property="og:description" content="Although this should be in its own research doc, here’s a summary of two separate things I’d like to get done with model trains image detection. There’s some overlap yet they are different." />


<meta name="twitter:card"        content="summary" />
<!-- meta name="twitter:site"    content="@flickr" / -->
<meta name="twitter:title"       content="Track Detection & OpenCV" />

<meta name="twitter:description" content="Although this should be in its own research doc, here’s a summary of two separate things I’d like to get done with model trains image detection. There’s some overlap yet they are different." />


<title>R’alf Dev Log</title>


<!-- custom fonts -->
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=VT323&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Workbench&display=swap" rel="stylesheet">

<!-- Custom styles for this template -->
<style type="text/css">
body {
    font-family: "Workbench", monospace;
    margin: 0;
    background: #000;
    color: #0A0;

    font-optical-sizing: auto;
    font-weight: 200;
    font-style: normal;
    font-variation-settings: "BLED" 0, "SCAN" 10;
}

.main {
    margin: 8px;
}

p, span {
    line-height: 1.2;
    text-align: justify;
}

p.console {
    margin: 0;
    padding: 0;
}

.container {
    max-width: 95%;
}

@media screen and (min-width: 600px) {
    .container {
        max-width: 60rem;
    }
}

.center-horiz {
    margin: auto;
}

.no-margin-container {
}

/* Header + Title */
.blog-header {
  margin-bottom: 3rem;
  background-color: #060;
  box-shadow: inset 0 -.1rem .25rem rgba(0,0,0,.1);
}



.title-container {
    color: #FF0;
    padding: 1rem;
    line-height: 1.5;
    font-weight: 500;
    font-size: 24px;
}

.title-container a {
    color: #FF0;
    text-decoration: none;
}

.post-container {
}

.bottom-container {
    margin-top: 8px;
    color: #FF0;
    background-color: #060;
    text-align: center;
    font-size: small;
    line-height: 1rem;
}

@media screen and (min-width: 600px) {
    .bottom-container {
        font-size: x-small;
    }
}

.post-title-container {
    position: relative;
    background-color: #060;
    padding: 0.5rem;
}

.post-title {
    display: inline;
    color: #FF0;
    font-weight: 500;
    font-size: 1.5em;
}

a.post-title-link {
    color: #FF0;
    text-decoration: none;
}

.post-cat {
    position: absolute;
    right: 0;
    top: 0;
    bottom: 0;
    padding: 0.25rem;
    background-color: #d0e0e3;
    color: #000;
    font-weight: 500;
    font-size: 1.5em;
}

a.post-cat-link {
    color: #000;
    text-decoration: none;
}

.post-cat-label {
    display: block;
    text-align: right;
    color: #000;
    font-size: 0.4em;
}

.prev-next-container {
    overflow: auto;
}

.prev-page {
    float: left;
    line-height: 2em;
}

.next-page {
    float: right;
    line-height: 2em;
}

h1, h2, h3, h4, h5, h6 {
    font-weight: bold;
}

.text-hide {
    font: 0/0 a;
    color: transparent;
    text-shadow: none;
    background-color: transparent;
    border: 0;
}

td p {
    margin: 0;
}


</style>
</head>

<body>

<header class="blog-header">

    <div class="title-container">
        <a href="http://www.alfray.com/ralf/">Ralf's Home Page</a>
        
        /
        <a href="0009.html">R’alf Dev Log</a>
        
    </div>
</header>

<main role="main">
<div class="main">
<div class="container center-horiz">

<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt"> </span></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt"></span></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt"> </span></p>
<p style="text-align:left"><span style="font-style:italic">The place where random ideas get written down and lost in time</span><span style="font-family:&quot;Workbench&quot;;font-size:12pt">.</span></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt"></span></p>

<div class="prev-next-container">


    <span class="prev-page"><a href="2020-07-18_projects_status.html">⇐ Newer Post</a><br/></span>
    <span class="next-page"><a href="2020-07-13_android_dark_mode.html">Older Post ⇒</a><br/></span>

</div>


    <div class="post-container">
    <div class="post-title-container"><h2 class="post-title">2020-07-15 - Track Detection & OpenCV</h2>
    <span class="post-cat" title="Category">
            <span class="post-cat-label">Category</span>
            <span class="post-cat-text">DEV</span>
    </span>
    </div>


    <p style="height:12pt;text-align:left"></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Although this should be in its own research doc, here’s a summary of two separate things I’d like to get done with model trains image detection. There’s some overlap yet they are different.</span></p>
<p style="height:12pt;text-align:left"></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">The first research subject is automated mapping: given a static image, find all tracks in the image, and create a visual schematic map of the network. There are two possible representations:</span></p>
<ul style="margin:0">
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Tracks form single paths (both lines and curves) with node intersections matching the frog of turnouts.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Track segments -- lines, curves, and turnouts.</span></li>
</ul>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">The first part of the problem is finding tracks in an image. </span></p>
<ul style="margin:0">
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">A track is defined as two parallel rails with perpendicular ties in the middle. An additional constraint is that rails always have the same distance. Some obvious complications arise when we have parallel tracks. Outlier cases such as heavily weathered tracks where ties are invisible could be omitted. The outlier case of road crossings should be optionally treated though.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Turnouts may be more difficult to detect. One approach is consider them the intersection of tracks, using a pure path/node approach. Turnouts geometry can be complex (e.g. double slip, X crossings). A first approach could just detect the “typical” simple turnout cases -- yard ladders, single sidings, and simple crossovers.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Elevation is expected to be a problem, as detailed below.</span></li>
</ul>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">The second part of the problem is to be able to map a layout by taking a series of “aerial” pictures, mapping track on each picture, and then merging them by detecting the edge overlaps.</span></p>
<ul style="margin:0">
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">One simplification is to get images that are as much “from the top” as possible. Some kind of perspective should be expected and corrected. However this erases elevation and would make it nearly impossible to detect.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Eye-level images would not be ideal as perspective is distorted and can make tract analysis a lot more difficult. There might be some compromise e.g. 45 degree view that would make the track still visible yet elevation possible to account for.</span></li>
</ul>
<p style="height:12pt;text-align:left"></p>
<p style="height:12pt;text-align:left"></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">The second research is detecting trains on the track. </span></p>
<p style="text-align:left"><span style="background-color:rgb(255, 255, 0)"></span></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">There are two axes for this: simplified for block detection, or fully automated.</span></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Simplified mode:</span></p>
<ul style="margin:0">
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">User draws / manually places markers on the image delineating block limits. Can include both linear track and curved portions. Interactive/visual confirmation is needed.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Some level of automated calibration is desired e.g. if camera/track moves (specific to my home segment test tracks).</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Block detection can use a simple image diff algorithm detecting motion on the specified blocks.Stopped trains become invisible.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Block detection can rely on a diff algorithm by comparing the track vs an “idle” state registered e.g. when the system starts.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">In all cases, we should be able to detect start/end parts of a train with respect to the defined block.</span></li>
</ul>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Fully automated mode:</span></p>
<ul style="margin:0">
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Relies on the previous research to detect track in the image.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">User still needs to map block boundaries, but this time against the schematic track.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Assuming we have an algorithm that detects tracks by detecting parallel rails and ties in between, block detection can be done by running the algorithm again on known block boundaries and checking where track cannot be detected because a train hides the track.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">We should be able to detect start/end parts of a train with respect to the defined block.</span></li>
</ul>
<p style="height:12pt;text-align:left"></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Latency and analysis time become interesting. The automation goal is to be able to not only detect when blocks are occupied, but also to stop trains. For example, detect a train is arriving in a station block, slow it down, and then use the start/end occupancy feedback to stop it where desired.</span></p>
<p style="height:12pt;text-align:left"></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Related CV keywords:</span></p>
<ul style="margin:0">
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Background segmentation.</span></li>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="-webkit-text-decoration-skip:none;color:rgb(17, 85, 204);text-decoration:underline;text-decoration-skip-ink:none"><a href="https://www.pyimagesearch.com/2015/01/19/find-distance-camera-objectmarker-using-python-opencv/" style="color:inherit;text-decoration:inherit">Distance finding via the “triangle” algorithm</a></span><span style="font-family:&quot;Workbench&quot;;font-size:12pt">.</span></li>
</ul>
<p style="height:12pt;text-align:left"></p>
<p style="height:12pt;text-align:left"></p>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">A third potential research is being able to identify trains. That part is a lot more open ended:</span></p>
<ul style="margin:0">
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Track-level camera and reading text of cars/engines going by. </span></li>
 <ul>
  <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Obvious question of speed making the image fuzzy.</span></li>
 </ul>
 <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">Aerial view and color/pattern matching known cars/engines top views.</span></li>
 <ul>
  <li style="padding-bottom:0pt;padding-left:0pt;padding-top:0pt;text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">This would be more of a fuzzy detection / only detecting classes.</span></li>
 </ul>
</ul>
<p style="text-align:left"><span style="font-family:&quot;Workbench&quot;;font-size:12pt">The idea here is to have dedicated “detection” hotspots (e.g. entrance/exit of yards) that can detect some engine numbers. Then some semantic model associates the presence of a track somewhere to that detected number based on continuity as the sole logic predicament. This only fails if e.g. trains are added/moved manually.</span></p>
<p style="height:12pt;text-align:left"></p>
<p style="height:12pt;text-align:left"></p>
<hr>
<p style="height:12pt;text-align:left"></p>


    </div>



<div class="prev-next-container">


    <span class="prev-page"><a href="2020-07-18_projects_status.html">⇐ Newer Post</a><br/></span>
    <span class="next-page"><a href="2020-07-13_android_dark_mode.html">Older Post ⇒</a><br/></span>

</div>

</div> <!-- container -->
</div> <!-- main -->

<div class="bottom-container">&nbsp;Generated on 2025-09-01 by Rig4j 0.1-Exp-0c45755&nbsp;</div>

</main>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-GCEQ33G1MB"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-GCEQ33G1MB');
</script>

</body>
</html>

